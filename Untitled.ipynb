{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20800, 5)\n",
      "(5200, 4)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('C:\\\\Users\\\\guilh_000\\\\Documents\\\\testFakeNews\\\\train.csv')\n",
    "test = pd.read_csv('C:\\\\Users\\\\guilh_000\\\\Documents\\\\testFakeNews\\\\test.csv')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pam Key                                                                               243\n",
       "admin                                                                                 193\n",
       "Jerome Hudson                                                                         166\n",
       "Charlie Spiering                                                                      141\n",
       "John Hayward                                                                          140\n",
       "Katherine Rodriguez                                                                   124\n",
       "Warner Todd Huston                                                                    122\n",
       "Ian Hanchett                                                                          119\n",
       "Breitbart News                                                                        118\n",
       "Daniel Nussbaum                                                                       112\n",
       "AWR Hawkins                                                                           107\n",
       "Jeff Poor                                                                             107\n",
       "Joel B. Pollak                                                                        106\n",
       "Trent Baker                                                                           102\n",
       "Breitbart London                                                                       97\n",
       "Bob Price                                                                              93\n",
       "Ben Kew                                                                                90\n",
       "Charlie Nash                                                                           88\n",
       "Pakalert                                                                               86\n",
       "Eddy Lavine                                                                            85\n",
       "Starkman                                                                               84\n",
       "Gillian                                                                                82\n",
       "Alex Ansary                                                                            82\n",
       "Editor                                                                                 81\n",
       "Lucas Nolan                                                                            80\n",
       "noreply@blogger.com (Alexander Light)                                                  80\n",
       "Dave Hodges                                                                            77\n",
       "Anonymous                                                                              77\n",
       "Breitbart Jerusalem                                                                    75\n",
       "John Binder                                                                            75\n",
       "                                                                                     ... \n",
       "Mitch Smith and Erik Eckholm                                                            1\n",
       "Meriem Kheira Peillet                                                                   1\n",
       "Refugees Invasion of Europe | Justice4Poland                                            1\n",
       "Alice Salles                                                                            1\n",
       "Hal Apeeno                                                                              1\n",
       "Lauren McCauley | Common Dreams                                                         1\n",
       "Uri Avnery                                                                              1\n",
       "David E. Sanger, Mark Mazzetti and Ben Hubbard                                          1\n",
       "Scot Vorse                                                                              1\n",
       "WakeUpAmericaPlease                                                                     1\n",
       "PaulTarsuss                                                                             1\n",
       "WindCharger                                                                             1\n",
       "hivdatingsites                                                                          1\n",
       "Vigilant Citizen                                                                        1\n",
       "David E. Sanger and Anne Barnard                                                        1\n",
       "Matthew Rosenberg, Mark Mazzetti and Eric Schmitt                                       1\n",
       "Marc Santora, Rukmini Callimachi and Adam Goldman                                       1\n",
       "Sharon Harrigan                                                                         1\n",
       "Michael D. Shear, Maggie Haberman and Alan Rappeport                                    1\n",
       "10 Habits That Will Make Your Life Easier &amp; More Peaceful - Wellness Solutions      1\n",
       "Saeed Al-Batati                                                                         1\n",
       "Bruce Feiler                                                                            1\n",
       "Bob Waldrop                                                                             1\n",
       "grayeagle                                                                               1\n",
       "Nida Najar and Hari Kumar                                                               1\n",
       "N. R. Kleinfield, Richard A. Oppel Jr. and Melissa Eddy                                 1\n",
       "Stanley Reed                                                                            1\n",
       "Parul Sehgal                                                                            1\n",
       "Bruce Baker                                                                             1\n",
       "Julfikar Ali Manik, Geeta Anand and Ellen Barry                                         1\n",
       "Name: author, Length: 4201, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def lemmatize_with_postag(sentence):\n",
    "    sent = TextBlob(sentence)\n",
    "    tag_dict = {\"J\":'a',\"N\":'n',\"V\":'v',\"R\":'r'}\n",
    "    words_and_tags = [(w, tag_dict.get(pos[0],'n'))for w, pos in sent.tags]\n",
    "    lemmatized_list = [wd.lemmatize(tag)for wd, tag in words_and_tags]\n",
    "    return \" \".join(lemmatized_list)\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "def normalizer(tweet):\n",
    "    punct = list(string.punctuation)\n",
    "    stop_words = stopwords.words('english')\n",
    "    additional_stop_words = ['RT','rt','via','...','http','twitpic','tinyurl','www']\n",
    "    stopword_list = punct + stop_words + additional_stop_words\n",
    "    \n",
    "    tweet = re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", tweet)\n",
    "    tweet_ = re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet)\n",
    "    tweet__ = re.sub(\"[^a-zA-Z]\", \" \", tweet_)\n",
    "    lemmatized = lemmatize_with_postag(tweet__)\n",
    "    tokens = nltk.word_tokenize(lemmatized)[2:]\n",
    "    lower_case = [l.lower() for l in tokens]\n",
    "    filtered_result = list(filter(lambda l: l not in stopword_list, lower_case))\n",
    "    return filtered_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        False\n",
       "title     False\n",
       "author    False\n",
       "text      False\n",
       "label     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        False\n",
       "title     False\n",
       "author    False\n",
       "text      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dropna(inplace=True)\n",
    "test.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def lemmatize_with_postag(sentence):\n",
    "    sent = TextBlob(sentence)\n",
    "    tag_dict = {\"J\":'a',\"N\":'n',\"V\":'v',\"R\":'r'}\n",
    "    words_and_tags = [(w, tag_dict.get(pos[0],'n'))for w, pos in sent.tags]\n",
    "    lemmatized_list = [wd.lemmatize(tag)for wd, tag in words_and_tags]\n",
    "    return \" \".join(lemmatized_list)\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "def normalizer(tweet):\n",
    "    punct = list(string.punctuation)\n",
    "    stop_words = stopwords.words('english')\n",
    "    additional_stop_words = ['RT','rt','via','...','http','twitpic','tinyurl','www']\n",
    "    stopword_list = punct + stop_words + additional_stop_words\n",
    "    \n",
    "    tweet = re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", tweet)\n",
    "    tweet_ = re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet)\n",
    "    tweet__ = re.sub(\"[^a-zA-Z]\", \" \", tweet_)\n",
    "    lemmatized = lemmatize_with_postag(tweet__)\n",
    "    tokens = nltk.word_tokenize(lemmatized)[2:]\n",
    "    lower_case = [l.lower() for l in tokens]\n",
    "    filtered_result = list(filter(lambda l: l not in stopword_list, lower_case))\n",
    "    return filtered_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['normalized'] = train.text.apply(normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['normalized'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
